{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b4b83d9d-ee81-4c2b-98b2-d9ac2accbadd",
   "metadata": {},
   "source": [
    "<a href=\"https://cognitiveclass.ai\"><img src=\"https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/IBMDeveloperSkillsNetwork-DL0101EN-SkillsNetwork/images/IDSN-logo.png\" width=\"400\"> </a>\n",
    "\n",
    "# Transformers with Keras\n",
    "\n",
    "Estimated time needed **45** mins\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b28e0c1b-fb88-4e66-a5ec-9416f965b717",
   "metadata": {},
   "source": [
    "In this lab, we will learn how to use the Keras library to build a transformer using a sequence-to-sequence architecture with self-attention for translation. We will train the model using a sample dataset and then use this model for English to Spanish translation.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15ad995e-7e6e-4702-9489-8c8d308b9cad",
   "metadata": {},
   "source": [
    "# Objectives for this Notebook    \n",
    "* How to use the Keras library to build transformers model\n",
    "* Train the transformer model using a given dataset\n",
    "* Use the trained transformer model to translate\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e65834b-ced0-4fb7-a683-ec577abb746e",
   "metadata": {},
   "source": [
    "<h2>Table of Contents</h2>\n",
    "\n",
    "\n",
    "<div class=\"alert alert-block alert-info\" style=\"margin-top: 20px\">\n",
    "\n",
    "<font size = 4>\n",
    "1. <a href=\"#Import-Keras-and-Packages\">Import Keras and Packages</a><br>\n",
    "2. <a href=\"#Step-1:-Data-Preparation\">Step 1: Data Preparation</a><br>\n",
    "3. <a href=\"#Step-2:-Self-Attention-Layer\">Step 2: Self-Attention Layer</a><br>\n",
    "4. <a href=\"#Step-3:-Model-Architecture\">Step 3: Model Architecture</a><br>\n",
    "5. <a href=\"#Step-4:-Training-the-Model\">Step 4: Training the Model</a><br>\n",
    "6. <a href=\"#Step-5:-Plotting-the-training-loss\">Step 5: Plotting the training loss</a><br>\n",
    "\n",
    "</font>\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3ec3b88-b498-4bbc-b802-69c99a87ad13",
   "metadata": {},
   "source": [
    "## Import Keras and Packages\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "625a449c-f2f2-4eda-bcec-e348978f2f8b",
   "metadata": {},
   "source": [
    "Let's start by importing the keras libraries and the packages that we would need to build a neural network.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6e9435e-0baa-4bc2-b5b3-252491560177",
   "metadata": {},
   "source": [
    "The following required libraries are __not__ pre-installed in the Skills Network Labs environment. __You will need to run the following cell__ to install them:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2f5bef90-b349-4692-95df-ace27d7688b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Ignoring invalid distribution ~atplotlib (C:\\Users\\pedro\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages)\n",
      "ERROR: Could not find a version that satisfies the requirement tensorflow==2.17.1 (from versions: 2.20.0rc0, 2.20.0)\n",
      "ERROR: No matching distribution found for tensorflow==2.17.1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting matplotlib==3.9.2\n",
      "  Using cached matplotlib-3.9.2-cp313-cp313-win_amd64.whl.metadata (11 kB)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in c:\\users\\pedro\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from matplotlib==3.9.2) (1.3.1)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\pedro\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from matplotlib==3.9.2) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in c:\\users\\pedro\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from matplotlib==3.9.2) (4.56.0)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in c:\\users\\pedro\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from matplotlib==3.9.2) (1.4.8)\n",
      "Requirement already satisfied: numpy>=1.23 in c:\\users\\pedro\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from matplotlib==3.9.2) (2.2.0)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\pedro\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from matplotlib==3.9.2) (24.2)\n",
      "Requirement already satisfied: pillow>=8 in c:\\users\\pedro\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from matplotlib==3.9.2) (11.3.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in c:\\users\\pedro\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from matplotlib==3.9.2) (3.2.3)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in c:\\users\\pedro\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from matplotlib==3.9.2) (2.9.0.post0)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\pedro\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from python-dateutil>=2.7->matplotlib==3.9.2) (1.17.0)\n",
      "Using cached matplotlib-3.9.2-cp313-cp313-win_amd64.whl (7.8 MB)\n",
      "Installing collected packages: matplotlib\n",
      "Successfully installed matplotlib-3.9.2\n",
      "==== All required libraries are installed =====\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Ignoring invalid distribution ~atplotlib (C:\\Users\\pedro\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution ~atplotlib (C:\\Users\\pedro\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution ~atplotlib (C:\\Users\\pedro\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages)\n"
     ]
    }
   ],
   "source": [
    "!pip install tensorflow==2.17.1\n",
    "!pip install matplotlib==3.9.2\n",
    "\n",
    "print(\"==== All required libraries are installed =====\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7339e193-e0ac-4bf6-8e2e-01d3949a2613",
   "metadata": {},
   "source": [
    "#### Suppress the tensorflow warning messages\n",
    "We use the following code to  suppress the warning messages due to use of CPU architechture for tensoflow.\n",
    "\n",
    "You may want to **comment out** these lines if you are using the GPU architechture\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3a499ae9-0af7-4074-8061-6fd07928d0cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#import os\n",
    "#os.environ['TF_ENABLE_ONEDNN_OPTS'] = '0'\n",
    "#os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b5b13e3-b59c-44f9-8a85-574a5d223a68",
   "metadata": {},
   "source": [
    "##### To use Keras, you will also need to install a backend framework – such as TensorFlow.\n",
    "\n",
    "If you install TensorFlow 2.16 or above, it will install Keras by default.\n",
    "\n",
    "We are using the CPU version of tensorflow since we are dealing with smaller datasets. \n",
    "You may install the GPU version of tensorflow on your machine to accelarate the processing of larger datasets\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa1420b9-c2bb-41f9-837e-63b934330c36",
   "metadata": {},
   "source": [
    "### Import the necessary libraries\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2e954f0b-2123-4da2-9495-4dc98248e1dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\pedro\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\google\\protobuf\\runtime_version.py:98: UserWarning: Protobuf gencode version 5.28.3 is exactly one major version older than the runtime version 6.31.1 at tensorflow/core/framework/attr_value.proto. Please update the gencode to avoid compatibility violations in the next runtime release.\n",
      "  warnings.warn(\n",
      "c:\\Users\\pedro\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\google\\protobuf\\runtime_version.py:98: UserWarning: Protobuf gencode version 5.28.3 is exactly one major version older than the runtime version 6.31.1 at tensorflow/core/framework/tensor.proto. Please update the gencode to avoid compatibility violations in the next runtime release.\n",
      "  warnings.warn(\n",
      "c:\\Users\\pedro\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\google\\protobuf\\runtime_version.py:98: UserWarning: Protobuf gencode version 5.28.3 is exactly one major version older than the runtime version 6.31.1 at tensorflow/core/framework/resource_handle.proto. Please update the gencode to avoid compatibility violations in the next runtime release.\n",
      "  warnings.warn(\n",
      "c:\\Users\\pedro\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\google\\protobuf\\runtime_version.py:98: UserWarning: Protobuf gencode version 5.28.3 is exactly one major version older than the runtime version 6.31.1 at tensorflow/core/framework/tensor_shape.proto. Please update the gencode to avoid compatibility violations in the next runtime release.\n",
      "  warnings.warn(\n",
      "c:\\Users\\pedro\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\google\\protobuf\\runtime_version.py:98: UserWarning: Protobuf gencode version 5.28.3 is exactly one major version older than the runtime version 6.31.1 at tensorflow/core/framework/types.proto. Please update the gencode to avoid compatibility violations in the next runtime release.\n",
      "  warnings.warn(\n",
      "c:\\Users\\pedro\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\google\\protobuf\\runtime_version.py:98: UserWarning: Protobuf gencode version 5.28.3 is exactly one major version older than the runtime version 6.31.1 at tensorflow/core/framework/full_type.proto. Please update the gencode to avoid compatibility violations in the next runtime release.\n",
      "  warnings.warn(\n",
      "c:\\Users\\pedro\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\google\\protobuf\\runtime_version.py:98: UserWarning: Protobuf gencode version 5.28.3 is exactly one major version older than the runtime version 6.31.1 at tensorflow/core/framework/function.proto. Please update the gencode to avoid compatibility violations in the next runtime release.\n",
      "  warnings.warn(\n",
      "c:\\Users\\pedro\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\google\\protobuf\\runtime_version.py:98: UserWarning: Protobuf gencode version 5.28.3 is exactly one major version older than the runtime version 6.31.1 at tensorflow/core/framework/node_def.proto. Please update the gencode to avoid compatibility violations in the next runtime release.\n",
      "  warnings.warn(\n",
      "c:\\Users\\pedro\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\google\\protobuf\\runtime_version.py:98: UserWarning: Protobuf gencode version 5.28.3 is exactly one major version older than the runtime version 6.31.1 at tensorflow/core/framework/op_def.proto. Please update the gencode to avoid compatibility violations in the next runtime release.\n",
      "  warnings.warn(\n",
      "c:\\Users\\pedro\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\google\\protobuf\\runtime_version.py:98: UserWarning: Protobuf gencode version 5.28.3 is exactly one major version older than the runtime version 6.31.1 at tensorflow/core/framework/graph.proto. Please update the gencode to avoid compatibility violations in the next runtime release.\n",
      "  warnings.warn(\n",
      "c:\\Users\\pedro\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\google\\protobuf\\runtime_version.py:98: UserWarning: Protobuf gencode version 5.28.3 is exactly one major version older than the runtime version 6.31.1 at tensorflow/core/framework/graph_debug_info.proto. Please update the gencode to avoid compatibility violations in the next runtime release.\n",
      "  warnings.warn(\n",
      "c:\\Users\\pedro\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\google\\protobuf\\runtime_version.py:98: UserWarning: Protobuf gencode version 5.28.3 is exactly one major version older than the runtime version 6.31.1 at tensorflow/core/framework/versions.proto. Please update the gencode to avoid compatibility violations in the next runtime release.\n",
      "  warnings.warn(\n",
      "c:\\Users\\pedro\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\google\\protobuf\\runtime_version.py:98: UserWarning: Protobuf gencode version 5.28.3 is exactly one major version older than the runtime version 6.31.1 at tensorflow/core/protobuf/config.proto. Please update the gencode to avoid compatibility violations in the next runtime release.\n",
      "  warnings.warn(\n",
      "c:\\Users\\pedro\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\google\\protobuf\\runtime_version.py:98: UserWarning: Protobuf gencode version 5.28.3 is exactly one major version older than the runtime version 6.31.1 at xla/tsl/protobuf/coordination_config.proto. Please update the gencode to avoid compatibility violations in the next runtime release.\n",
      "  warnings.warn(\n",
      "c:\\Users\\pedro\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\google\\protobuf\\runtime_version.py:98: UserWarning: Protobuf gencode version 5.28.3 is exactly one major version older than the runtime version 6.31.1 at tensorflow/core/framework/cost_graph.proto. Please update the gencode to avoid compatibility violations in the next runtime release.\n",
      "  warnings.warn(\n",
      "c:\\Users\\pedro\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\google\\protobuf\\runtime_version.py:98: UserWarning: Protobuf gencode version 5.28.3 is exactly one major version older than the runtime version 6.31.1 at tensorflow/core/framework/step_stats.proto. Please update the gencode to avoid compatibility violations in the next runtime release.\n",
      "  warnings.warn(\n",
      "c:\\Users\\pedro\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\google\\protobuf\\runtime_version.py:98: UserWarning: Protobuf gencode version 5.28.3 is exactly one major version older than the runtime version 6.31.1 at tensorflow/core/framework/allocation_description.proto. Please update the gencode to avoid compatibility violations in the next runtime release.\n",
      "  warnings.warn(\n",
      "c:\\Users\\pedro\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\google\\protobuf\\runtime_version.py:98: UserWarning: Protobuf gencode version 5.28.3 is exactly one major version older than the runtime version 6.31.1 at tensorflow/core/framework/tensor_description.proto. Please update the gencode to avoid compatibility violations in the next runtime release.\n",
      "  warnings.warn(\n",
      "c:\\Users\\pedro\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\google\\protobuf\\runtime_version.py:98: UserWarning: Protobuf gencode version 5.28.3 is exactly one major version older than the runtime version 6.31.1 at tensorflow/core/protobuf/cluster.proto. Please update the gencode to avoid compatibility violations in the next runtime release.\n",
      "  warnings.warn(\n",
      "c:\\Users\\pedro\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\google\\protobuf\\runtime_version.py:98: UserWarning: Protobuf gencode version 5.28.3 is exactly one major version older than the runtime version 6.31.1 at tensorflow/core/protobuf/debug.proto. Please update the gencode to avoid compatibility violations in the next runtime release.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from keras.models import Model\n",
    "from keras.layers import Input, LSTM, Dense, Embedding, Dropout\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras import backend as K\n",
    "from keras.layers import Layer\n",
    "import warnings\n",
    "warnings.simplefilter('ignore', FutureWarning)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01fe576a-5e25-4f72-8bd3-04ed7faacc37",
   "metadata": {},
   "source": [
    "# Step 1: Data Preparation\n",
    "We start by define the sentences and text for translation training\n",
    "Sentence Pairs: Defines a small dataset of English-Spanish sentence pairs.\n",
    "Target Sequences:\n",
    "Prepends \"startseq\" and appends \"endseq\" to each target sentence for the decoder to learn when to start and stop translating.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e389a3a7-8c76-402e-aa65-02abf1d5b4a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sample parallel sentences (English -> Spanish)\n",
    "input_texts = [\n",
    "    \"Hello.\", \"How are you?\", \"I am learning machine translation.\", \"What is your name?\", \"I love programming.\"\n",
    "]\n",
    "target_texts = [\n",
    "    \"Hola.\", \"¿Cómo estás?\", \"Estoy aprendiendo traducción automática.\", \"¿Cuál es tu nombre?\", \"Me encanta programar.\"\n",
    "]\n",
    "\n",
    "target_texts = [\"startseq \" + x + \" endseq\" for x in target_texts]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "082b7e53-ac7b-446d-8b0f-009fe2fb1406",
   "metadata": {},
   "source": [
    "## Next, we convert the text from the sentences to tokens and create a vocabulary\n",
    "Tokenization: Uses Tokenizer to convert words into numerical sequences.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f882437d-9ad6-40e0-8dd0-23924cae7a24",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tokenization\n",
    "input_tokenizer = Tokenizer()\n",
    "input_tokenizer.fit_on_texts(input_texts)\n",
    "input_sequences = input_tokenizer.texts_to_sequences(input_texts)\n",
    "\n",
    "output_tokenizer = Tokenizer()\n",
    "output_tokenizer.fit_on_texts(target_texts)\n",
    "output_sequences = output_tokenizer.texts_to_sequences(target_texts)\n",
    "\n",
    "input_vocab_size = len(input_tokenizer.word_index) + 1\n",
    "output_vocab_size = len(output_tokenizer.word_index) + 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3334dbbf-edcc-4aed-8f54-44e12dd73572",
   "metadata": {},
   "source": [
    "### Now pad the corresponding sentences\n",
    "Padding: Ensures all sequences have the same length.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2cb4844e-2095-4e8a-9dd2-3e84cb82bed9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Padding\n",
    "max_input_length = max([len(seq) for seq in input_sequences])\n",
    "max_output_length = max([len(seq) for seq in output_sequences])\n",
    "\n",
    "input_sequences = pad_sequences(input_sequences, maxlen=max_input_length, padding='post')\n",
    "output_sequences = pad_sequences(output_sequences, maxlen=max_output_length, padding='post')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "85cd65a3-f255-4149-8843-388f76f08763",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare the target data for training\n",
    "decoder_input_data = output_sequences[:, :-1]\n",
    "decoder_output_data = output_sequences[:, 1:]\n",
    "\n",
    "# Convert to one-hot\n",
    "decoder_output_data = np.array([np.eye(output_vocab_size)[seq] for seq in decoder_output_data])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e6895d9-6971-41c6-a64a-0ba0309d7619",
   "metadata": {},
   "source": [
    "# Step 2: Self-Attention Layer\n",
    "Self-attention is a mechanism that allows a model to **focus on relevant parts of the input sequence** while processing each word. This is particularly useful in:\n",
    "1) Machine Translation (e.g., aligning words correctly)\n",
    "2) Text Summarization\n",
    "3) Speech Recognition\n",
    "4) Image Processing (Vision Transformers)\n",
    "In this implementation, self-attention is used for text based sequence-to-sequence modeling.\n",
    "\n",
    "\n",
    "Self-Attention works for a given an input sequence by computing a weighted representation of all words for each position. It does so using three key components:\n",
    "\n",
    "1. Query **(Q)**, Key **(K)**, and Value **(V)** Matrices\n",
    "For each word (token) in a sequence:\n",
    "\n",
    "Query (Q): What this word is looking for.\n",
    "Key (K): What this word represents.\n",
    "Value (V): The actual information in the word.\n",
    "\n",
    "2. Compute **Attention Scores**\n",
    "Next, we **calculate the similarity between each query and key** using dot-product attention:\n",
    "Each word in a sequence attends to every other word based on these scores.\n",
    "\n",
    "3. Apply **Scaling & Softmax**\n",
    "Since dot-product values can be large, we scale them. \n",
    "Next, Applying softmax converts scores into attention weights:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b388dc6d-66e7-43a6-8b83-cacd8e6095be",
   "metadata": {},
   "source": [
    "### Self-Attention class\n",
    "In this implementation of self-attention layer:\n",
    "1. We first initialize the weights in the **build** method, where:\n",
    "    1. **self.Wq**, **self.Wk**, **self.Wv** are the trainable weight matrices.\n",
    "    2. Their **shape is (feature_dim, feature_dim)**, meaning they transform input features into Q, K, and V representations.\n",
    "2. Applying Attention using **call** method. The **call()** method:\n",
    "   1. Computes **Q, K, V** by multiplying inputs (encoder/decoder output) with their respective weight matrices.\n",
    "   2. Computes **dot-product attention scores** using K.batch_dot(q, k, axes=[2, 2]), resulting in a (batch_size, seq_len, seq_len) matrix.\n",
    "   3. **Scales** the scores to avoid large values.\n",
    "   4. Applies **softmax** to normalize the attention scores.\n",
    "   5. **Multiplies attention weights with V** to get the final output.\n",
    "3. The **compute_output_shape** method defines the shape of the output tensor after the layer processes an input.\n",
    "    1. The output shape of the Self-Attention layer **remains the same** as the input shape.\n",
    "    2. The attention mechanism **transforms** the input but does not change its dimensions.4\n",
    "    3. If the attention layer changed the shape, you would modify compute_output_shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f247862b-a21f-485a-8b63-562beb42fb17",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the Self-Attention Layer\n",
    "class SelfAttention(Layer):\n",
    "    def __init__(self, **kwargs):\n",
    "        super(SelfAttention, self).__init__(**kwargs)\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        feature_dim = input_shape[-1]\n",
    "        # Weight matrices for Q, K, V\n",
    "        self.Wq = self.add_weight(shape=(feature_dim, feature_dim), \n",
    "                                  initializer='glorot_uniform', \n",
    "                                  trainable=True, \n",
    "                                  name='Wq')\n",
    "        self.Wk = self.add_weight(shape=(feature_dim, feature_dim), \n",
    "                                  initializer='glorot_uniform', \n",
    "                                  trainable=True, \n",
    "                                  name='Wk')\n",
    "        self.Wv = self.add_weight(shape=(feature_dim, feature_dim), \n",
    "                                  initializer='glorot_uniform', \n",
    "                                  trainable=True, \n",
    "                                  name='Wv')\n",
    "        super(SelfAttention, self).build(input_shape)\n",
    "\n",
    "    def call(self, inputs):\n",
    "        # Linear projections\n",
    "        q = K.dot(inputs, self.Wq)  # Query\n",
    "        k = K.dot(inputs, self.Wk)  # Key\n",
    "        v = K.dot(inputs, self.Wv)  # Value\n",
    "\n",
    "        # Scaled Dot-Product Attention\n",
    "        scores = K.batch_dot(q, k, axes=[2, 2])  # (batch, seq_len, seq_len)\n",
    "        scores = scores / K.sqrt(K.cast(K.shape(k)[-1], dtype=K.floatx()))  # Scale\n",
    "        attention_weights = K.softmax(scores, axis=-1)  # Normalize\n",
    "\n",
    "        # Weighted sum of values\n",
    "        output = K.batch_dot(attention_weights, v)  # (batch, seq_len, feature_dim)\n",
    "        return output\n",
    "\n",
    "    def compute_output_shape(self, input_shape):\n",
    "        return input_shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2510724e-c3a2-4e77-bea7-4f8667479c14",
   "metadata": {},
   "source": [
    "# Step 3: Model Architecture\n",
    "The model follows an Encoder-Decoder structure:\n",
    "\n",
    "### Encoder:\n",
    "1) Takes input sentences (padded and tokenized).\n",
    "2) Uses an Embedding layer (word representations) + LSTM (to process sequences).\n",
    "    1. The LSTMs are used as the **help process variable-length input sentences** and generate meaningful translations.\n",
    "4) Outputs context vectors (hidden & cell states).\n",
    "\n",
    "### Attention Layer\n",
    "1) Applied to both the encoder and decoder outputs.\n",
    "2) Helps the decoder focus on relevant words during translation.\n",
    "\n",
    "### Decoder\n",
    "1) Receives target sequences (shifted one step ahead).\n",
    "2) Uses an LSTM with encoder states as initial states.\n",
    "3) Applies self-attention for better learning.\n",
    "4) Uses a Dense layer (Softmax) to predict the next word.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "65b60708-e44a-41ee-b1ef-0608235ba39b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"functional\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)        </span>┃<span style=\"font-weight: bold\"> Output Shape      </span>┃<span style=\"font-weight: bold\">    Param # </span>┃<span style=\"font-weight: bold\"> Connected to      </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n",
       "│ input_layer         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">5</span>)         │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                 │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ input_layer_1       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">5</span>)         │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                 │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ embedding           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">5</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)    │      <span style=\"color: #00af00; text-decoration-color: #00af00\">4,096</span> │ input_layer[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>] │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)         │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ embedding_1         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">5</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)    │      <span style=\"color: #00af00; text-decoration-color: #00af00\">4,352</span> │ input_layer_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)         │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ lstm (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)         │ [(<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">5</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>),  │    <span style=\"color: #00af00; text-decoration-color: #00af00\">525,312</span> │ embedding[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
       "│                     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>),      │            │                   │\n",
       "│                     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)]      │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ lstm_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)       │ [(<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">5</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>),  │    <span style=\"color: #00af00; text-decoration-color: #00af00\">525,312</span> │ embedding_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>… │\n",
       "│                     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>),      │            │ lstm[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>],       │\n",
       "│                     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)]      │            │ lstm[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>]        │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ additive_attention  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">5</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)    │        <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> │ lstm_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],     │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">AdditiveAttention</span>) │                   │            │ lstm[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]        │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ concatenate         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">5</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)    │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ lstm_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],     │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Concatenate</span>)       │                   │            │ additive_attenti… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">5</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">17</span>)     │      <span style=\"color: #00af00; text-decoration-color: #00af00\">8,721</span> │ concatenate[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>] │\n",
       "└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)       \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape     \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m   Param #\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mConnected to     \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n",
       "│ input_layer         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m5\u001b[0m)         │          \u001b[38;5;34m0\u001b[0m │ -                 │\n",
       "│ (\u001b[38;5;33mInputLayer\u001b[0m)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ input_layer_1       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m5\u001b[0m)         │          \u001b[38;5;34m0\u001b[0m │ -                 │\n",
       "│ (\u001b[38;5;33mInputLayer\u001b[0m)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ embedding           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m5\u001b[0m, \u001b[38;5;34m256\u001b[0m)    │      \u001b[38;5;34m4,096\u001b[0m │ input_layer[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m] │\n",
       "│ (\u001b[38;5;33mEmbedding\u001b[0m)         │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ embedding_1         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m5\u001b[0m, \u001b[38;5;34m256\u001b[0m)    │      \u001b[38;5;34m4,352\u001b[0m │ input_layer_1[\u001b[38;5;34m0\u001b[0m]… │\n",
       "│ (\u001b[38;5;33mEmbedding\u001b[0m)         │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ lstm (\u001b[38;5;33mLSTM\u001b[0m)         │ [(\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m5\u001b[0m, \u001b[38;5;34m256\u001b[0m),  │    \u001b[38;5;34m525,312\u001b[0m │ embedding[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
       "│                     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m),      │            │                   │\n",
       "│                     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)]      │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ lstm_1 (\u001b[38;5;33mLSTM\u001b[0m)       │ [(\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m5\u001b[0m, \u001b[38;5;34m256\u001b[0m),  │    \u001b[38;5;34m525,312\u001b[0m │ embedding_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m… │\n",
       "│                     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m),      │            │ lstm[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m1\u001b[0m],       │\n",
       "│                     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)]      │            │ lstm[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m2\u001b[0m]        │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ additive_attention  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m5\u001b[0m, \u001b[38;5;34m256\u001b[0m)    │        \u001b[38;5;34m256\u001b[0m │ lstm_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],     │\n",
       "│ (\u001b[38;5;33mAdditiveAttention\u001b[0m) │                   │            │ lstm[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]        │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ concatenate         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m5\u001b[0m, \u001b[38;5;34m512\u001b[0m)    │          \u001b[38;5;34m0\u001b[0m │ lstm_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],     │\n",
       "│ (\u001b[38;5;33mConcatenate\u001b[0m)       │                   │            │ additive_attenti… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dense (\u001b[38;5;33mDense\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m5\u001b[0m, \u001b[38;5;34m17\u001b[0m)     │      \u001b[38;5;34m8,721\u001b[0m │ concatenate[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m] │\n",
       "└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">1,068,049</span> (4.07 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m1,068,049\u001b[0m (4.07 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">1,068,049</span> (4.07 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m1,068,049\u001b[0m (4.07 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from tensorflow.keras.layers import AdditiveAttention, Concatenate, Dense, Embedding, Input, LSTM\n",
    "from tensorflow.keras.models import Model\n",
    " \n",
    "# Encoder\n",
    "encoder_inputs = Input(shape=(max_input_length,))\n",
    "encoder_embedding = Embedding(input_vocab_size, 256)(encoder_inputs)\n",
    "encoder_lstm = LSTM(256, return_sequences=True, return_state=True)\n",
    "encoder_outputs, state_h, state_c = encoder_lstm(encoder_embedding)\n",
    "encoder_states = [state_h, state_c]\n",
    " \n",
    "# Decoder\n",
    "decoder_inputs = Input(shape=(max_output_length - 1,))\n",
    "decoder_embedding = Embedding(output_vocab_size, 256)(decoder_inputs)\n",
    "decoder_lstm = LSTM(256, return_sequences=True, return_state=True)\n",
    "decoder_outputs, _, _ = decoder_lstm(decoder_embedding, initial_state=encoder_states)\n",
    " \n",
    "# Attention: decoder attends to encoder outputs\n",
    "attention = AdditiveAttention()\n",
    "attention_output = attention([decoder_outputs, encoder_outputs])\n",
    " \n",
    "# Combine decoder outputs with attention context\n",
    "decoder_concat = Concatenate(axis=-1)([decoder_outputs, attention_output])\n",
    " \n",
    "# Final Dense layer\n",
    "decoder_dense = Dense(output_vocab_size, activation='softmax')\n",
    "decoder_outputs = decoder_dense(decoder_concat)\n",
    " \n",
    "# Full Model\n",
    "model = Model([encoder_inputs, decoder_inputs], decoder_outputs)\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    " \n",
    "# Summary\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b7b90f2-f4ca-4c7a-baae-ca52da565cee",
   "metadata": {},
   "source": [
    "# Step 4: Training the Model\n",
    "Uses categorical_crossentropy as the loss function since output words are one-hot encoded.\n",
    "Trains using Adam optimizer for 100 epochs.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "669ef3f0-6e75-4487-a021-53b38922a35e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2s/step - accuracy: 0.0000e+00 - loss: 2.8358\n",
      "Epoch 2/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - accuracy: 0.3200 - loss: 2.8046\n",
      "Epoch 3/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - accuracy: 0.3200 - loss: 2.7719\n",
      "Epoch 4/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - accuracy: 0.3200 - loss: 2.7347\n",
      "Epoch 5/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - accuracy: 0.3200 - loss: 2.6897\n",
      "Epoch 6/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - accuracy: 0.3200 - loss: 2.6326\n",
      "Epoch 7/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - accuracy: 0.2800 - loss: 2.5580\n",
      "Epoch 8/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - accuracy: 0.2800 - loss: 2.4596\n",
      "Epoch 9/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - accuracy: 0.2800 - loss: 2.3335\n",
      "Epoch 10/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - accuracy: 0.2800 - loss: 2.1916\n",
      "Epoch 11/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - accuracy: 0.2400 - loss: 2.0832\n",
      "Epoch 12/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - accuracy: 0.2400 - loss: 2.0605\n",
      "Epoch 13/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - accuracy: 0.2800 - loss: 2.0525\n",
      "Epoch 14/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - accuracy: 0.2800 - loss: 1.9962\n",
      "Epoch 15/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - accuracy: 0.2800 - loss: 1.9204\n",
      "Epoch 16/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - accuracy: 0.3600 - loss: 1.8623\n",
      "Epoch 17/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - accuracy: 0.4000 - loss: 1.8174\n",
      "Epoch 18/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - accuracy: 0.4400 - loss: 1.7667\n",
      "Epoch 19/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - accuracy: 0.4400 - loss: 1.7073\n",
      "Epoch 20/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - accuracy: 0.4800 - loss: 1.6438\n",
      "Epoch 21/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - accuracy: 0.5600 - loss: 1.5800\n",
      "Epoch 22/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - accuracy: 0.5200 - loss: 1.5179\n",
      "Epoch 23/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - accuracy: 0.4800 - loss: 1.4583\n",
      "Epoch 24/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step - accuracy: 0.4800 - loss: 1.4010\n",
      "Epoch 25/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - accuracy: 0.4800 - loss: 1.3421\n",
      "Epoch 26/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - accuracy: 0.4400 - loss: 1.2767\n",
      "Epoch 27/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - accuracy: 0.4800 - loss: 1.2042\n",
      "Epoch 28/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - accuracy: 0.5600 - loss: 1.1307\n",
      "Epoch 29/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - accuracy: 0.6000 - loss: 1.0614\n",
      "Epoch 30/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - accuracy: 0.6400 - loss: 0.9960\n",
      "Epoch 31/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - accuracy: 0.6400 - loss: 0.9348\n",
      "Epoch 32/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - accuracy: 0.6400 - loss: 0.8796\n",
      "Epoch 33/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - accuracy: 0.7200 - loss: 0.8257\n",
      "Epoch 34/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - accuracy: 0.8000 - loss: 0.7695\n",
      "Epoch 35/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - accuracy: 0.8400 - loss: 0.7162\n",
      "Epoch 36/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - accuracy: 0.8800 - loss: 0.6675\n",
      "Epoch 37/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - accuracy: 0.9600 - loss: 0.6191\n",
      "Epoch 38/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - accuracy: 1.0000 - loss: 0.5739\n",
      "Epoch 39/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - accuracy: 1.0000 - loss: 0.5322\n",
      "Epoch 40/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - accuracy: 1.0000 - loss: 0.4902\n",
      "Epoch 41/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - accuracy: 1.0000 - loss: 0.4487\n",
      "Epoch 42/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - accuracy: 1.0000 - loss: 0.4093\n",
      "Epoch 43/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 1.0000 - loss: 0.3740\n",
      "Epoch 44/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - accuracy: 1.0000 - loss: 0.3439\n",
      "Epoch 45/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - accuracy: 1.0000 - loss: 0.3149\n",
      "Epoch 46/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - accuracy: 1.0000 - loss: 0.2869\n",
      "Epoch 47/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - accuracy: 1.0000 - loss: 0.2640\n",
      "Epoch 48/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - accuracy: 1.0000 - loss: 0.2435\n",
      "Epoch 49/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - accuracy: 1.0000 - loss: 0.2238\n",
      "Epoch 50/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - accuracy: 1.0000 - loss: 0.2058\n",
      "Epoch 51/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - accuracy: 1.0000 - loss: 0.1894\n",
      "Epoch 52/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - accuracy: 1.0000 - loss: 0.1746\n",
      "Epoch 53/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - accuracy: 1.0000 - loss: 0.1588\n",
      "Epoch 54/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 1.0000 - loss: 0.1459\n",
      "Epoch 55/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - accuracy: 1.0000 - loss: 0.1343\n",
      "Epoch 56/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - accuracy: 1.0000 - loss: 0.1229\n",
      "Epoch 57/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - accuracy: 1.0000 - loss: 0.1123\n",
      "Epoch 58/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - accuracy: 1.0000 - loss: 0.1030\n",
      "Epoch 59/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - accuracy: 1.0000 - loss: 0.0943\n",
      "Epoch 60/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - accuracy: 1.0000 - loss: 0.0863\n",
      "Epoch 61/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - accuracy: 1.0000 - loss: 0.0797\n",
      "Epoch 62/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - accuracy: 1.0000 - loss: 0.0733\n",
      "Epoch 63/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - accuracy: 1.0000 - loss: 0.0672\n",
      "Epoch 64/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - accuracy: 1.0000 - loss: 0.0620\n",
      "Epoch 65/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - accuracy: 1.0000 - loss: 0.0575\n",
      "Epoch 66/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 1.0000 - loss: 0.0533\n",
      "Epoch 67/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - accuracy: 1.0000 - loss: 0.0494\n",
      "Epoch 68/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - accuracy: 1.0000 - loss: 0.0460\n",
      "Epoch 69/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 1.0000 - loss: 0.0427\n",
      "Epoch 70/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - accuracy: 1.0000 - loss: 0.0396\n",
      "Epoch 71/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - accuracy: 1.0000 - loss: 0.0370\n",
      "Epoch 72/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - accuracy: 1.0000 - loss: 0.0346\n",
      "Epoch 73/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - accuracy: 1.0000 - loss: 0.0325\n",
      "Epoch 74/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - accuracy: 1.0000 - loss: 0.0304\n",
      "Epoch 75/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - accuracy: 1.0000 - loss: 0.0285\n",
      "Epoch 76/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - accuracy: 1.0000 - loss: 0.0268\n",
      "Epoch 77/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - accuracy: 1.0000 - loss: 0.0253\n",
      "Epoch 78/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - accuracy: 1.0000 - loss: 0.0238\n",
      "Epoch 79/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - accuracy: 1.0000 - loss: 0.0225\n",
      "Epoch 80/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - accuracy: 1.0000 - loss: 0.0213\n",
      "Epoch 81/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - accuracy: 1.0000 - loss: 0.0202\n",
      "Epoch 82/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - accuracy: 1.0000 - loss: 0.0191\n",
      "Epoch 83/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - accuracy: 1.0000 - loss: 0.0182\n",
      "Epoch 84/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - accuracy: 1.0000 - loss: 0.0173\n",
      "Epoch 85/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - accuracy: 1.0000 - loss: 0.0164\n",
      "Epoch 86/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - accuracy: 1.0000 - loss: 0.0157\n",
      "Epoch 87/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - accuracy: 1.0000 - loss: 0.0150\n",
      "Epoch 88/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - accuracy: 1.0000 - loss: 0.0143\n",
      "Epoch 89/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - accuracy: 1.0000 - loss: 0.0137\n",
      "Epoch 90/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 1.0000 - loss: 0.0131\n",
      "Epoch 91/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - accuracy: 1.0000 - loss: 0.0126\n",
      "Epoch 92/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - accuracy: 1.0000 - loss: 0.0121\n",
      "Epoch 93/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - accuracy: 1.0000 - loss: 0.0117\n",
      "Epoch 94/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - accuracy: 1.0000 - loss: 0.0112\n",
      "Epoch 95/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - accuracy: 1.0000 - loss: 0.0108\n",
      "Epoch 96/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - accuracy: 1.0000 - loss: 0.0105\n",
      "Epoch 97/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - accuracy: 1.0000 - loss: 0.0101\n",
      "Epoch 98/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - accuracy: 1.0000 - loss: 0.0098\n",
      "Epoch 99/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - accuracy: 1.0000 - loss: 0.0095\n",
      "Epoch 100/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - accuracy: 1.0000 - loss: 0.0092\n"
     ]
    }
   ],
   "source": [
    "# Step 6: Train the Model\n",
    "history_glorot_adam = model.fit([input_sequences, decoder_input_data], decoder_output_data, epochs=100, batch_size=16)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a963f90e-f99e-43e3-8fdd-19c975d02676",
   "metadata": {},
   "source": [
    "# Step 5: Plotting the training loss\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8f5a9e39-c627-4a83-86ee-cffdb7cfe6a4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plotting training loss\n",
    "import matplotlib.pyplot as plt\n",
    "plt.plot(history_glorot_adam.history['loss'])\n",
    "plt.title('Training Loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9f973b2-fa19-4be1-9fcb-91e674485587",
   "metadata": {},
   "source": [
    "# Awesome, now you have succesfully trained a transformers model.\n",
    "### Now let's try some practice excercises\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89620358-beaf-4d69-a513-3ee5c51ca074",
   "metadata": {},
   "source": [
    "## Practice excercise 1\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98270e97-f36c-4e0f-9a15-6753744b57d0",
   "metadata": {},
   "source": [
    "In this practice exercise, let's train the model using \"he_uniform\" initializer instead of \"glorot_uniform\". Then, compare the training loss between model using \"glorot_uniform\" vs \"he_uniform\" initializers by plotting them using matplotlib\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1e895342-b116-41e4-894a-8c649a55cb52",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2s/step - accuracy: 0.0800 - loss: 2.8296\n",
      "Epoch 2/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - accuracy: 0.3600 - loss: 2.7980\n",
      "Epoch 3/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - accuracy: 0.3200 - loss: 2.7638\n",
      "Epoch 4/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - accuracy: 0.3200 - loss: 2.7241\n",
      "Epoch 5/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - accuracy: 0.3200 - loss: 2.6753\n",
      "Epoch 6/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - accuracy: 0.3200 - loss: 2.6128\n",
      "Epoch 7/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - accuracy: 0.3200 - loss: 2.5310\n",
      "Epoch 8/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - accuracy: 0.3200 - loss: 2.4238\n",
      "Epoch 9/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - accuracy: 0.3200 - loss: 2.2899\n",
      "Epoch 10/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - accuracy: 0.2800 - loss: 2.1483\n",
      "Epoch 11/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - accuracy: 0.2400 - loss: 2.0503\n",
      "Epoch 12/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - accuracy: 0.2400 - loss: 2.0304\n",
      "Epoch 13/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - accuracy: 0.2400 - loss: 2.0159\n",
      "Epoch 14/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - accuracy: 0.3200 - loss: 1.9628\n",
      "Epoch 15/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - accuracy: 0.3600 - loss: 1.9031\n",
      "Epoch 16/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - accuracy: 0.4400 - loss: 1.8557\n",
      "Epoch 17/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - accuracy: 0.4000 - loss: 1.8008\n",
      "Epoch 18/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - accuracy: 0.4400 - loss: 1.7378\n",
      "Epoch 19/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - accuracy: 0.5600 - loss: 1.6778\n",
      "Epoch 20/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - accuracy: 0.6000 - loss: 1.6253\n",
      "Epoch 21/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - accuracy: 0.6000 - loss: 1.5774\n",
      "Epoch 22/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - accuracy: 0.6000 - loss: 1.5300\n",
      "Epoch 23/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - accuracy: 0.5200 - loss: 1.4803\n",
      "Epoch 24/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - accuracy: 0.5200 - loss: 1.4266\n",
      "Epoch 25/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - accuracy: 0.4800 - loss: 1.3672\n",
      "Epoch 26/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - accuracy: 0.5600 - loss: 1.3004\n",
      "Epoch 27/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 0.6000 - loss: 1.2267\n",
      "Epoch 28/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - accuracy: 0.6400 - loss: 1.1504\n",
      "Epoch 29/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - accuracy: 0.6800 - loss: 1.0772\n",
      "Epoch 30/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - accuracy: 0.7200 - loss: 1.0106\n",
      "Epoch 31/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 0.7200 - loss: 0.9500\n",
      "Epoch 32/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - accuracy: 0.7600 - loss: 0.8907\n",
      "Epoch 33/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - accuracy: 0.8000 - loss: 0.8297\n",
      "Epoch 34/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - accuracy: 0.8800 - loss: 0.7696\n",
      "Epoch 35/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - accuracy: 0.8400 - loss: 0.7122\n",
      "Epoch 36/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - accuracy: 0.8800 - loss: 0.6570\n",
      "Epoch 37/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - accuracy: 0.9600 - loss: 0.6074\n",
      "Epoch 38/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - accuracy: 0.9600 - loss: 0.5645\n",
      "Epoch 39/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - accuracy: 0.9600 - loss: 0.5217\n",
      "Epoch 40/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - accuracy: 1.0000 - loss: 0.4771\n",
      "Epoch 41/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - accuracy: 1.0000 - loss: 0.4346\n",
      "Epoch 42/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - accuracy: 1.0000 - loss: 0.3960\n",
      "Epoch 43/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 1.0000 - loss: 0.3624\n",
      "Epoch 44/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 1.0000 - loss: 0.3320\n",
      "Epoch 45/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 1.0000 - loss: 0.3018\n",
      "Epoch 46/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - accuracy: 1.0000 - loss: 0.2744\n",
      "Epoch 47/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - accuracy: 1.0000 - loss: 0.2515\n",
      "Epoch 48/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - accuracy: 1.0000 - loss: 0.2295\n",
      "Epoch 49/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - accuracy: 1.0000 - loss: 0.2095\n",
      "Epoch 50/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - accuracy: 1.0000 - loss: 0.1927\n",
      "Epoch 51/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 1.0000 - loss: 0.1758\n",
      "Epoch 52/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - accuracy: 1.0000 - loss: 0.1597\n",
      "Epoch 53/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 1.0000 - loss: 0.1463\n",
      "Epoch 54/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 1.0000 - loss: 0.1339\n",
      "Epoch 55/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - accuracy: 1.0000 - loss: 0.1218\n",
      "Epoch 56/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - accuracy: 1.0000 - loss: 0.1110\n",
      "Epoch 57/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - accuracy: 1.0000 - loss: 0.1015\n",
      "Epoch 58/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - accuracy: 1.0000 - loss: 0.0922\n",
      "Epoch 59/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - accuracy: 1.0000 - loss: 0.0840\n",
      "Epoch 60/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step - accuracy: 1.0000 - loss: 0.0771\n",
      "Epoch 61/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - accuracy: 1.0000 - loss: 0.0705\n",
      "Epoch 62/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - accuracy: 1.0000 - loss: 0.0645\n",
      "Epoch 63/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - accuracy: 1.0000 - loss: 0.0595\n",
      "Epoch 64/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - accuracy: 1.0000 - loss: 0.0547\n",
      "Epoch 65/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - accuracy: 1.0000 - loss: 0.0502\n",
      "Epoch 66/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - accuracy: 1.0000 - loss: 0.0464\n",
      "Epoch 67/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - accuracy: 1.0000 - loss: 0.0430\n",
      "Epoch 68/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - accuracy: 1.0000 - loss: 0.0398\n",
      "Epoch 69/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - accuracy: 1.0000 - loss: 0.0370\n",
      "Epoch 70/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - accuracy: 1.0000 - loss: 0.0345\n",
      "Epoch 71/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - accuracy: 1.0000 - loss: 0.0322\n",
      "Epoch 72/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - accuracy: 1.0000 - loss: 0.0300\n",
      "Epoch 73/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - accuracy: 1.0000 - loss: 0.0280\n",
      "Epoch 74/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - accuracy: 1.0000 - loss: 0.0263\n",
      "Epoch 75/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - accuracy: 1.0000 - loss: 0.0247\n",
      "Epoch 76/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - accuracy: 1.0000 - loss: 0.0232\n",
      "Epoch 77/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - accuracy: 1.0000 - loss: 0.0218\n",
      "Epoch 78/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - accuracy: 1.0000 - loss: 0.0206\n",
      "Epoch 79/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - accuracy: 1.0000 - loss: 0.0195\n",
      "Epoch 80/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - accuracy: 1.0000 - loss: 0.0184\n",
      "Epoch 81/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - accuracy: 1.0000 - loss: 0.0175\n",
      "Epoch 82/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - accuracy: 1.0000 - loss: 0.0166\n",
      "Epoch 83/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - accuracy: 1.0000 - loss: 0.0158\n",
      "Epoch 84/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - accuracy: 1.0000 - loss: 0.0150\n",
      "Epoch 85/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - accuracy: 1.0000 - loss: 0.0143\n",
      "Epoch 86/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - accuracy: 1.0000 - loss: 0.0137\n",
      "Epoch 87/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - accuracy: 1.0000 - loss: 0.0131\n",
      "Epoch 88/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - accuracy: 1.0000 - loss: 0.0125\n",
      "Epoch 89/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - accuracy: 1.0000 - loss: 0.0120\n",
      "Epoch 90/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - accuracy: 1.0000 - loss: 0.0116\n",
      "Epoch 91/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - accuracy: 1.0000 - loss: 0.0111\n",
      "Epoch 92/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - accuracy: 1.0000 - loss: 0.0107\n",
      "Epoch 93/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - accuracy: 1.0000 - loss: 0.0103\n",
      "Epoch 94/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - accuracy: 1.0000 - loss: 0.0099\n",
      "Epoch 95/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - accuracy: 1.0000 - loss: 0.0096\n",
      "Epoch 96/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - accuracy: 1.0000 - loss: 0.0093\n",
      "Epoch 97/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - accuracy: 1.0000 - loss: 0.0090\n",
      "Epoch 98/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - accuracy: 1.0000 - loss: 0.0087\n",
      "Epoch 99/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - accuracy: 1.0000 - loss: 0.0084\n",
      "Epoch 100/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - accuracy: 1.0000 - loss: 0.0082\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Define the Self-Attention Layer\n",
    "class SelfAttention(Layer):\n",
    "    def __init__(self, **kwargs):\n",
    "        super(SelfAttention, self).__init__(**kwargs)\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        feature_dim = input_shape[-1]\n",
    "        # Weight matrices for Q, K, V\n",
    "        self.Wq = self.add_weight(shape=(feature_dim, feature_dim), \n",
    "                                  initializer='he_uniform', \n",
    "                                  trainable=True, \n",
    "                                  name='Wq')\n",
    "        self.Wk = self.add_weight(shape=(feature_dim, feature_dim), \n",
    "                                  initializer='he_uniform', \n",
    "                                  trainable=True, \n",
    "                                  name='Wk')\n",
    "        self.Wv = self.add_weight(shape=(feature_dim, feature_dim), \n",
    "                                  initializer='he_uniform', \n",
    "                                  trainable=True, \n",
    "                                  name='Wv')\n",
    "        super(SelfAttention, self).build(input_shape)\n",
    "\n",
    "    def call(self, inputs):\n",
    "        # Linear projections\n",
    "        q = K.dot(inputs, self.Wq)  # Query\n",
    "        k = K.dot(inputs, self.Wk)  # Key\n",
    "        v = K.dot(inputs, self.Wv)  # Value\n",
    "\n",
    "        # Scaled Dot-Product Attention\n",
    "        scores = K.batch_dot(q, k, axes=[2, 2])  # (batch, seq_len, seq_len)\n",
    "        scores = scores / K.sqrt(K.cast(K.shape(k)[-1], dtype=K.floatx()))  # Scale\n",
    "        attention_weights = K.softmax(scores, axis=-1)  # Normalize\n",
    "\n",
    "        # Weighted sum of values\n",
    "        output = K.batch_dot(attention_weights, v)  # (batch, seq_len, feature_dim)\n",
    "        return output\n",
    "\n",
    "    def compute_output_shape(self, input_shape):\n",
    "        return input_shape\n",
    "    \n",
    "\n",
    "from tensorflow.keras.layers import AdditiveAttention, Concatenate, Dense, Embedding, Input, LSTM\n",
    "from tensorflow.keras.models import Model\n",
    " \n",
    "# Encoder\n",
    "encoder_inputs = Input(shape=(max_input_length,))\n",
    "encoder_embedding = Embedding(input_vocab_size, 256)(encoder_inputs)\n",
    "encoder_lstm = LSTM(256, return_sequences=True, return_state=True)\n",
    "encoder_outputs, state_h, state_c = encoder_lstm(encoder_embedding)\n",
    "encoder_states = [state_h, state_c]\n",
    " \n",
    "# Decoder\n",
    "decoder_inputs = Input(shape=(max_output_length - 1,))\n",
    "decoder_embedding = Embedding(output_vocab_size, 256)(decoder_inputs)\n",
    "decoder_lstm = LSTM(256, return_sequences=True, return_state=True)\n",
    "decoder_outputs, _, _ = decoder_lstm(decoder_embedding, initial_state=encoder_states)\n",
    " \n",
    "# Attention: decoder attends to encoder outputs\n",
    "attention = AdditiveAttention()\n",
    "attention_output = attention([decoder_outputs, encoder_outputs])\n",
    " \n",
    "# Combine decoder outputs with attention context\n",
    "decoder_concat = Concatenate(axis=-1)([decoder_outputs, attention_output])\n",
    " \n",
    "# Final Dense layer\n",
    "decoder_dense = Dense(output_vocab_size, activation='softmax')\n",
    "decoder_outputs = decoder_dense(decoder_concat)\n",
    " \n",
    "# Full Model\n",
    "model = Model([encoder_inputs, decoder_inputs], decoder_outputs)\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    " \n",
    "# Summary\n",
    "#model.summary()\n",
    "\n",
    "# Step 6: Train the Model\n",
    "history_he_adam = model.fit([input_sequences, decoder_input_data], decoder_output_data, epochs=100, batch_size=16)\n",
    "\n",
    "# Plotting training loss\n",
    "import matplotlib.pyplot as plt\n",
    "plt.plot(history_he_adam.history['loss'])\n",
    "plt.title('Training Loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4ce9951-1ad4-46f6-95c6-6b2c96cb6d17",
   "metadata": {},
   "source": [
    "Double-click <b>here</b> for the solution.\n",
    "\n",
    "<!-- Your answer is below:\n",
    "\n",
    "\n",
    "#Define the Self-Attention Layer\n",
    "class SelfAttention(Layer):\n",
    "    def __init__(self, **kwargs):\n",
    "        super(SelfAttention, self).__init__(**kwargs)\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        feature_dim = input_shape[-1]\n",
    "        # Weight matrices for Q, K, V\n",
    "        self.Wq = self.add_weight(shape=(feature_dim, feature_dim), \n",
    "                                  initializer='he_uniform', \n",
    "                                  trainable=True, \n",
    "                                  name='Wq')\n",
    "        self.Wk = self.add_weight(shape=(feature_dim, feature_dim), \n",
    "                                  initializer='he_uniform', \n",
    "                                  trainable=True, \n",
    "                                  name='Wk')\n",
    "        self.Wv = self.add_weight(shape=(feature_dim, feature_dim), \n",
    "                                  initializer='he_uniform', \n",
    "                                  trainable=True, \n",
    "                                  name='Wv')\n",
    "        super(SelfAttention, self).build(input_shape)\n",
    "\n",
    "    def call(self, inputs):\n",
    "        # Linear projections\n",
    "        q = K.dot(inputs, self.Wq)  # Query\n",
    "        k = K.dot(inputs, self.Wk)  # Key\n",
    "        v = K.dot(inputs, self.Wv)  # Value\n",
    "\n",
    "        # Scaled Dot-Product Attention\n",
    "        scores = K.batch_dot(q, k, axes=[2, 2])  # (batch, seq_len, seq_len)\n",
    "        scores = scores / K.sqrt(K.cast(K.shape(k)[-1], dtype=K.floatx()))  # Scale\n",
    "        attention_weights = K.softmax(scores, axis=-1)  # Normalize\n",
    "\n",
    "        # Weighted sum of values\n",
    "        output = K.batch_dot(attention_weights, v)  # (batch, seq_len, feature_dim)\n",
    "        return output\n",
    "\n",
    "    def compute_output_shape(self, input_shape):\n",
    "        return input_shape\n",
    "\n",
    "    \n",
    "#Encoder\n",
    "encoder_inputs = Input(shape=(max_input_length,))\n",
    "encoder_embedding = Embedding(input_vocab_size, 256)(encoder_inputs)\n",
    "encoder_lstm = LSTM(256, return_sequences=True, return_state=True)\n",
    "encoder_outputs, state_h, state_c = encoder_lstm(encoder_embedding)\n",
    "encoder_states = [state_h, state_c]\n",
    "\n",
    "#Decoder\n",
    "decoder_inputs = Input(shape=(max_output_length - 1,), name=\"decoder_inputs\")\n",
    "decoder_embedding = Embedding(output_vocab_size, 256, name=\"decoder_embedding\")(decoder_inputs)\n",
    "decoder_lstm = LSTM(256, return_sequences=True, return_state=True, name=\"decoder_lstm\")\n",
    "decoder_outputs, _, _ = decoder_lstm(decoder_embedding, initial_state=encoder_states)\n",
    "\n",
    "#Attention Mechanism\n",
    "attention = AdditiveAttention(name=\"attention_layer\")\n",
    "attention_output = attention([decoder_outputs, encoder_outputs])\n",
    "\n",
    "# Concatenate context with decoder outputs\n",
    "decoder_concat = Concatenate(axis=-1, name=\"concat_layer\")([decoder_outputs, attention_output])\n",
    "\n",
    "# Final Dense Layer\n",
    "decoder_dense = Dense(output_vocab_size, activation='softmax', name=\"output_dense\")\n",
    "decoder_outputs = decoder_dense(decoder_concat)\n",
    "\n",
    "#Full Model\n",
    "model = Model([encoder_inputs, decoder_inputs], decoder_outputs)\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "\n",
    "#Step 6: Train the Model\n",
    "history_he = model.fit([input_sequences, decoder_input_data], decoder_output_data, epochs=100, batch_size=16)\n",
    "\n",
    "#Plotting training losses for glorot_uniform and he_uniform inititalizers\n",
    "import matplotlib.pyplot as plt\n",
    "plt.plot(history_glorot_adam.history['loss'], label=\"glorot_uniform\", color='red')\n",
    "plt.plot(history_he.history['loss'], label=\"he_uniform\", color='blue')\n",
    "plt.title('Training Loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "\n",
    "-->\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e6bf5c9-9be4-4989-9746-0888d7dc44bb",
   "metadata": {},
   "source": [
    "## Practice excercise 2\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37a217c3-bc48-4367-a8c7-095b29b496e2",
   "metadata": {},
   "source": [
    "In this practice exercise, try to use adaptive gradient optimizer instead of adam. Then, plot and compare the results between adam and adaptive gradient optimizers\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ba9c5a1e-ee7a-49a4-94ee-075879692abf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2s/step - accuracy: 1.0000 - loss: 0.0079\n",
      "Epoch 2/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - accuracy: 1.0000 - loss: 0.0079\n",
      "Epoch 3/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - accuracy: 1.0000 - loss: 0.0079\n",
      "Epoch 4/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - accuracy: 1.0000 - loss: 0.0079\n",
      "Epoch 5/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - accuracy: 1.0000 - loss: 0.0079\n",
      "Epoch 6/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - accuracy: 1.0000 - loss: 0.0079\n",
      "Epoch 7/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - accuracy: 1.0000 - loss: 0.0079\n",
      "Epoch 8/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - accuracy: 1.0000 - loss: 0.0079\n",
      "Epoch 9/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - accuracy: 1.0000 - loss: 0.0079\n",
      "Epoch 10/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - accuracy: 1.0000 - loss: 0.0079\n",
      "Epoch 11/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - accuracy: 1.0000 - loss: 0.0079\n",
      "Epoch 12/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - accuracy: 1.0000 - loss: 0.0079\n",
      "Epoch 13/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - accuracy: 1.0000 - loss: 0.0079\n",
      "Epoch 14/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - accuracy: 1.0000 - loss: 0.0079\n",
      "Epoch 15/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - accuracy: 1.0000 - loss: 0.0079\n",
      "Epoch 16/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - accuracy: 1.0000 - loss: 0.0079\n",
      "Epoch 17/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - accuracy: 1.0000 - loss: 0.0079\n",
      "Epoch 18/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - accuracy: 1.0000 - loss: 0.0079\n",
      "Epoch 19/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - accuracy: 1.0000 - loss: 0.0079\n",
      "Epoch 20/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - accuracy: 1.0000 - loss: 0.0079\n",
      "Epoch 21/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - accuracy: 1.0000 - loss: 0.0079\n",
      "Epoch 22/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - accuracy: 1.0000 - loss: 0.0079\n",
      "Epoch 23/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - accuracy: 1.0000 - loss: 0.0079\n",
      "Epoch 24/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - accuracy: 1.0000 - loss: 0.0079\n",
      "Epoch 25/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - accuracy: 1.0000 - loss: 0.0079\n",
      "Epoch 26/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - accuracy: 1.0000 - loss: 0.0079\n",
      "Epoch 27/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - accuracy: 1.0000 - loss: 0.0079\n",
      "Epoch 28/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 1.0000 - loss: 0.0079\n",
      "Epoch 29/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - accuracy: 1.0000 - loss: 0.0079\n",
      "Epoch 30/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - accuracy: 1.0000 - loss: 0.0079\n",
      "Epoch 31/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - accuracy: 1.0000 - loss: 0.0079\n",
      "Epoch 32/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - accuracy: 1.0000 - loss: 0.0079\n",
      "Epoch 33/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - accuracy: 1.0000 - loss: 0.0079\n",
      "Epoch 34/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - accuracy: 1.0000 - loss: 0.0079\n",
      "Epoch 35/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - accuracy: 1.0000 - loss: 0.0079\n",
      "Epoch 36/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - accuracy: 1.0000 - loss: 0.0079\n",
      "Epoch 37/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 1.0000 - loss: 0.0079\n",
      "Epoch 38/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - accuracy: 1.0000 - loss: 0.0079\n",
      "Epoch 39/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - accuracy: 1.0000 - loss: 0.0079\n",
      "Epoch 40/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - accuracy: 1.0000 - loss: 0.0079\n",
      "Epoch 41/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - accuracy: 1.0000 - loss: 0.0079\n",
      "Epoch 42/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - accuracy: 1.0000 - loss: 0.0079\n",
      "Epoch 43/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - accuracy: 1.0000 - loss: 0.0079\n",
      "Epoch 44/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - accuracy: 1.0000 - loss: 0.0079\n",
      "Epoch 45/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - accuracy: 1.0000 - loss: 0.0079\n",
      "Epoch 46/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - accuracy: 1.0000 - loss: 0.0079\n",
      "Epoch 47/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - accuracy: 1.0000 - loss: 0.0079\n",
      "Epoch 48/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - accuracy: 1.0000 - loss: 0.0079\n",
      "Epoch 49/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - accuracy: 1.0000 - loss: 0.0079\n",
      "Epoch 50/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - accuracy: 1.0000 - loss: 0.0079\n",
      "Epoch 51/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - accuracy: 1.0000 - loss: 0.0079\n",
      "Epoch 52/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - accuracy: 1.0000 - loss: 0.0079\n",
      "Epoch 53/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - accuracy: 1.0000 - loss: 0.0079\n",
      "Epoch 54/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - accuracy: 1.0000 - loss: 0.0079\n",
      "Epoch 55/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - accuracy: 1.0000 - loss: 0.0079\n",
      "Epoch 56/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - accuracy: 1.0000 - loss: 0.0079\n",
      "Epoch 57/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - accuracy: 1.0000 - loss: 0.0079\n",
      "Epoch 58/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - accuracy: 1.0000 - loss: 0.0079\n",
      "Epoch 59/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - accuracy: 1.0000 - loss: 0.0079\n",
      "Epoch 60/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - accuracy: 1.0000 - loss: 0.0079\n",
      "Epoch 61/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - accuracy: 1.0000 - loss: 0.0079\n",
      "Epoch 62/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - accuracy: 1.0000 - loss: 0.0079\n",
      "Epoch 63/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - accuracy: 1.0000 - loss: 0.0079\n",
      "Epoch 64/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - accuracy: 1.0000 - loss: 0.0079\n",
      "Epoch 65/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - accuracy: 1.0000 - loss: 0.0079\n",
      "Epoch 66/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - accuracy: 1.0000 - loss: 0.0079\n",
      "Epoch 67/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - accuracy: 1.0000 - loss: 0.0079\n",
      "Epoch 68/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 1.0000 - loss: 0.0079\n",
      "Epoch 69/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - accuracy: 1.0000 - loss: 0.0079\n",
      "Epoch 70/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - accuracy: 1.0000 - loss: 0.0079\n",
      "Epoch 71/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - accuracy: 1.0000 - loss: 0.0079\n",
      "Epoch 72/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - accuracy: 1.0000 - loss: 0.0079\n",
      "Epoch 73/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - accuracy: 1.0000 - loss: 0.0079\n",
      "Epoch 74/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 1.0000 - loss: 0.0079\n",
      "Epoch 75/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - accuracy: 1.0000 - loss: 0.0079\n",
      "Epoch 76/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - accuracy: 1.0000 - loss: 0.0079\n",
      "Epoch 77/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - accuracy: 1.0000 - loss: 0.0079\n",
      "Epoch 78/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - accuracy: 1.0000 - loss: 0.0079\n",
      "Epoch 79/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - accuracy: 1.0000 - loss: 0.0079\n",
      "Epoch 80/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - accuracy: 1.0000 - loss: 0.0079\n",
      "Epoch 81/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - accuracy: 1.0000 - loss: 0.0079\n",
      "Epoch 82/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - accuracy: 1.0000 - loss: 0.0079\n",
      "Epoch 83/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - accuracy: 1.0000 - loss: 0.0079\n",
      "Epoch 84/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - accuracy: 1.0000 - loss: 0.0079\n",
      "Epoch 85/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - accuracy: 1.0000 - loss: 0.0079\n",
      "Epoch 86/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - accuracy: 1.0000 - loss: 0.0079\n",
      "Epoch 87/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - accuracy: 1.0000 - loss: 0.0079\n",
      "Epoch 88/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - accuracy: 1.0000 - loss: 0.0079\n",
      "Epoch 89/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - accuracy: 1.0000 - loss: 0.0079\n",
      "Epoch 90/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - accuracy: 1.0000 - loss: 0.0079\n",
      "Epoch 91/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - accuracy: 1.0000 - loss: 0.0079\n",
      "Epoch 92/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - accuracy: 1.0000 - loss: 0.0079\n",
      "Epoch 93/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - accuracy: 1.0000 - loss: 0.0079\n",
      "Epoch 94/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 1.0000 - loss: 0.0079\n",
      "Epoch 95/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - accuracy: 1.0000 - loss: 0.0079\n",
      "Epoch 96/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - accuracy: 1.0000 - loss: 0.0079\n",
      "Epoch 97/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - accuracy: 1.0000 - loss: 0.0079\n",
      "Epoch 98/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step - accuracy: 1.0000 - loss: 0.0079\n",
      "Epoch 99/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - accuracy: 1.0000 - loss: 0.0079\n",
      "Epoch 100/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - accuracy: 1.0000 - loss: 0.0079\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Full Model\n",
    "model = Model([encoder_inputs, decoder_inputs], decoder_outputs)\n",
    "model.compile(optimizer='adagrad', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "\n",
    "#Step 6: Train the Model\n",
    "history_adagrad = model.fit([input_sequences, decoder_input_data], decoder_output_data, epochs=100, batch_size=16)\n",
    "\n",
    "#Plotting training losses for glorot_uniform and he_uniform inititalizers\n",
    "import matplotlib.pyplot as plt\n",
    "plt.plot(history_glorot_adam.history['loss'], label=\"adam\", color='red')\n",
    "plt.plot(history_adagrad.history['loss'], label=\"adagrad\", color='blue')\n",
    "plt.title('Training Loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5be3344-d99e-4532-8259-aaca3d28fd2a",
   "metadata": {},
   "source": [
    "Double-click <b>here</b> for the solution.\n",
    "\n",
    "<!-- Your answer is below:\n",
    "\n",
    "#Full Model\n",
    "model = Model([encoder_inputs, decoder_inputs], decoder_outputs)\n",
    "model.compile(optimizer='adagrad', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "\n",
    "#Step 6: Train the Model\n",
    "history_adagrad = model.fit([input_sequences, decoder_input_data], decoder_output_data, epochs=100, batch_size=16)\n",
    "\n",
    "#Plotting training losses for glorot_uniform and he_uniform inititalizers\n",
    "import matplotlib.pyplot as plt\n",
    "plt.plot(history_glorot_adam.history['loss'], label=\"adam\", color='red')\n",
    "plt.plot(history_adagrad.history['loss'], label=\"adagrad\", color='blue')\n",
    "plt.title('Training Loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "-->\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "013d17a2-ba8b-493e-aac6-ea5dd60013b6",
   "metadata": {},
   "source": [
    "## Thank you for completing this lab!\n",
    "\n",
    "This notebook was created by [Aman Aggarwal](https://www.linkedin.com/in/aggarwal-aman/). I hope you found this lab interesting and educational. Feel free to contact me if you have any questions!\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab4406ec-6313-4cee-ae98-be46c835fe57",
   "metadata": {},
   "source": [
    "<!--\n",
    "## Change Log\n",
    "\n",
    "|  Date (YYYY-MM-DD) |  Version | Changed By  |  Change Description |\n",
    "|---|---|---|---|\n",
    "| 2024-11-20  | 1.0  | Aman  |  Created the lab |\n",
    "<hr>\n",
    "-->\n",
    "## <h3 align=\"center\"> © IBM Corporation. All rights reserved. <h3/>\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  },
  "prev_pub_hash": "3a07fb4049049613c9f3bf3a0aaeeac466433593dd808e2778bab531403fe8a9"
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
